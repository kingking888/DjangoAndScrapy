步骤：

scrapy部分
1. 编写爬虫脚本，配置custom_settings
2.静态页面的直接scrapy脚本
3.动态页面需结合selenium，在middlewares中创建相应的脚本
4.创建mysql对应管道，存入mysql相应表（创建class）

django部分
1.执行python manage.py inspectdb，针对已有的数据库自动生成新的models
   （或者手动编写models）
2.执行python manage.py makemigrations，生成一个migrations文件夹，该文件夹的内容就是数据库要执行的内容
3.执行python manage.py migrate，执行之前生成的migrations文件，这一步才是操作数据库的一步，执行完成后，数据库里面会新增一张表
4.views中编写启动爬虫函数和读取相应数据库函数
5.配置相应urls
6.templates目录中index.html编写相应按钮
7.templates目录中新增相对应html文件



执行：
python manage.py runserver 192.168.31.221:9999  （启动django，manage.py同目录下）

scrapyd-deploy yiyao -p ScrapyPage （运行部署爬虫改动后重新部署，scrapy.cfg同目录下）

scrapyd 启动